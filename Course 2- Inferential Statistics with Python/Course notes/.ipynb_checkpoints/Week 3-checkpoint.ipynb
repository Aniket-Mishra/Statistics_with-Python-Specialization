{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a test for a population proportion\n",
    "\n",
    "## Hypothesis Testing\n",
    "**Why do we do Hypothesis tests?** <br>\n",
    "Could the value of the parameter be maru maru? <br>\n",
    "we have an idea of what it could be but we have no idea if it's correct or not. <br>\n",
    "with that question we try and collect data to support that claim or go against that claim. <br>\n",
    "\n",
    "## C.S. Mott Children't hospital\n",
    "\n",
    "## Research Question:\n",
    "In previous years, 52% of parents believed that electronics and social media was the cause of their teenager's lack of sleep. Do more parents today believe that their teenager's lack of sleep is caused due to electronics and social media?\n",
    "<br>\n",
    "Population: Parents with teenages aged 13-18 <br>\n",
    "Parameter of interest = p or the population proportion <br>\n",
    "**Test for a significance increase in the proportion of parents with a teenager who believe that electronics and social media is the cause for lack of sleep.** <br>\n",
    "\n",
    "### We set our hypothesis first, even before we collect our data so that we do not influence in what we believe.\n",
    "\n",
    "H0 : Null Hypothesis : p = 0.52 -> Lack of sleep is caused by electronics<br>\n",
    "Ha : Alternate hypothesis : p ? 0.52 (? in [>, <. !=]) <br>\n",
    "In our case here Ha : p > 0.52 as the statement above says check for a significance increase. <br>\n",
    "**p here is the population proportion of parents with a teenager who believe that electronics and social media is the cause of their teenager's lack of sleep** <br>\n",
    "alpha = 0.05 -> Significance level : When we find something to be significant when p is < 0.05 : cutoff point <br>\n",
    "After this we will collect the data.\n",
    "### Assumptions:\n",
    "1. Random sample of parents\n",
    "2. Large enough sample size \" n*p0 and n*(1-p0) > 10\n",
    "\n",
    "<br>\n",
    "From the poll after collection data, we got: <br>\n",
    "**Best estimate of p is p^ = 0.56** <br>\n",
    "\n",
    "\n",
    "### Test statistic:\n",
    "**(Best estimate - Hypothesized estimate) / Standard Error of estimate** <br>\n",
    "**(p^ - po) / s.e** <br>\n",
    "se(p^) = sqrt( (p . (1-p)) / n ) <br>\n",
    "since we do not know what p is, <br>\n",
    "**se(p^) = sqrt( (p . (1-p)) / n ) -> Null Standard Error**<br> \n",
    "Since we **do not know** what **p** is, we will use **p0 to calculate our se(p^)** <br>\n",
    "**se(p^) = sqrt( (p0. (1-p0)) / n ) \n",
    "<br>\n",
    "Finally, <br>\n",
    "**Z(test statistic) = (p^ - p0) / null se(p^)**\n",
    "<br><br>\n",
    "Z statistic means that our observed sample proportion is **(value of Z)** null standard errors above our hypothesized population. <br>\n",
    "Here, <br>\n",
    "Z = (p^ - p0) / s.e <br>\n",
    "se = sqrt( (p0 . (1-p0)) / n ) <br>\n",
    "se = 0.0157 <br>\n",
    "Z = (0.56 - 0.52) / 0.0157 <br>\n",
    "Z = 2.555 <br>\n",
    "We will consider this a normal distribution as we are calculating a proportion (population statistic) and our sample size is large enough. <br>\n",
    "**Test Statistic Interpretation** <br>\n",
    "Z = 2.555 <br>\n",
    "That means that our observed sample proportion is 2.555 null standard errors above our hypothesized population proportion. <br>\n",
    "\n",
    "### Test Statistic Distribution\n",
    "* A Z test statistic is another random variable! It has a distribution.\n",
    "* The Z test statistic will always follow a N(0,1), i.e. Mean = 0 and std-dev = 1 \n",
    "* This is due to us centering and scaling our original data.\n",
    "    * Z = (p^ - p0) / se(p^)\n",
    "        * p^-p0 centers our data\n",
    "        * se(p^) scales our data\n",
    "\n",
    "### P Value\n",
    "![p-value](img/p-value-single-prop.png)\n",
    "<br><br>\n",
    "**We get the P-value from a Z-table or by calculating it from some programming language. Here, p-value = 0.0053 which means that it is less than our significance level, alpha, so our null hypothesis sounds rediculous, and we will reject it.** <br>\n",
    "p-value = 0.0053 < alpha =0.05  <br>\n",
    "Reject the Null Hypothesis (H0:p = 0.52) <br>\n",
    "**There is sufficient evidence to conclude that the population proportion of parents with a teenager who believe that electronics and social media is the cause for lack of sleep is greater than 52% (our alternate hypothesis)** <br>\n",
    "**We would fail to reject a Null Hypothesis when the p-value is > alpha.** <br>\n",
    "\n",
    "### Summary\n",
    "* 4 main steps to a hypothesis test\n",
    "    - stating a  hypothesis and selecting a significance level (alpha)\n",
    "    - Checking assumptions\n",
    "    - Calculating a test statistic and gettinga  p-value from the test statistic\n",
    "    - drawing conclusions from the p-value\n",
    "* The Z test statistic distribution is N(0,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up a test of difference in population proportions\n",
    "**Research Question**\n",
    "Is there a significance difference between the population proportions of parents of black children and parents of hispanic children who report that their child has some swimming lessons?  <br>\n",
    "**Populations**  <br>\n",
    "1. All parents of black children aged 6-18 (group - 1)\n",
    "2. All parents of hispanic children aged 6-18 (group - 2)\n",
    "**Parameter of interest** <br>\n",
    "p1 - p2 <br>\n",
    "**Test for a significant difference in the population proportions of parents reporting their child has had swimming lessons at the to% significance level.** <br>\n",
    "H0: p1-p2 = 0 <br>\n",
    "**Null Hypothesis always has to have the equal sign**\n",
    "ha: p1-p2 ? 0  <br>\n",
    "**In this case, alternate will be != as we just want to see if the two population proportions are unequal. we do not care what direction the inequality is in**\n",
    "Thus, <br>\n",
    "Ha: p1-p2 != 0  <br>\n",
    "alpha = 0.10 <br>\n",
    "\n",
    "## Assumptions\n",
    "1. Two independent random samples\n",
    "2. Large enough sample size, i.e. n1p^, p1(1-p^), n2p^, n2(1-p^) >= 10\n",
    "\n",
    "## Checking Assumptions\n",
    "p^ = (91+120)/(247+308) = 211/555 = 0.38 <br>\n",
    "247(0.38) = 94 <br>\n",
    "247(1-0.38) = 153 <br>\n",
    "308(0.38) = 117 <br>\n",
    "308(1-0.38) = 191 <br>\n",
    "**If this assumption is not met, we can perform different tests that bypass this assumption** <br>\n",
    "**p1^ = 91/247 = 0.37, 1 = black <br>\n",
    "p2^ = 120/308 = 0.39, 2 = hispanic** <br>\n",
    "**p1^ - p2^ = 0.37 - 0.39 = -0.02 <br>\n",
    "Here, as the difference is negative, we see that the sample proportion for black children is smaller than the sample proportion of hispanic childten. <br>\n",
    "\n",
    "## Testing Difference in population Proportions\n",
    "\n",
    "## Test Statistic\n",
    "**(Best estimate - Hypothesized estimate) / Standard error of estimate**\n",
    "<br>\n",
    "(p1^ - p2^ -0) / se(p^) <br>\n",
    "se(p^) = sqrt( p^(1-p^) . { (1/n1) + (1/n2) } )\n",
    "<br>\n",
    "sq(p^) = 0.041 <br>\n",
    "p1^-p2^-0 = -0.02 <br>\n",
    "Z = -0.02/0.041 <br>\n",
    "Z = -0.48 <br>\n",
    "\n",
    "### Test Statistic Interpretation\n",
    "Z = -0.48 <br>\n",
    "That means that our observed difference in sample proportions is 0.48 estimated standard errors below our hypothesized mean of equal propulation proportions.  <br>\n",
    "\n",
    "### p-value:\n",
    "![p-value](img/p-value-double-prop.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision and conclusion\n",
    "p-value = 0.63 > 0.10 = alpha -> Fail to reject the null hypothesis <br>\n",
    "**This does not mean we accept the null hypothesis, it only means that we do not have enough evidence to reject it.** <br>\n",
    "* This means we don't have evidence against equal population proportions\n",
    " Formally, based on our sample and our p-value, we fail to reject the null hypothesis. We conclude that there is no significant difference between the population proportion of parents of black and hispanic children who report their child has had swimming lessons.  <br>\n",
    " **In essence, it means that the population proportion of both populations are roughly equivalent, meaning it's not like black or hispanic children have more/less swimming lessons that their counterparts.** <br>\n",
    " ## Alternative Approaches\n",
    " 1. CHhi-Square (x^2) Test\n",
    "     * Different Hypotheses\n",
    "     * Require two-sided hypothesis : Does not work for p1 > p2 or p1 < p2. Works for p1 != p2\n",
    "     * same conclusion* as population proportion test (one we did above)\n",
    "     * As two-sided hypothesis with proportions\n",
    "2. Fisher's Exact Test\n",
    "    * Allows one-sided hypothesis\n",
    "    * typocally small sample sizes\n",
    "    * Calculates different p-values compared to population proportion test\n",
    "    * Compared to same setup of proportions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# p-values, p-hacking, and so on\n",
    "p-hacking: or any other statistic hacking happens when the researcher intentionally/unintentionally manipulates the data such that it gives us a different result than it would otherwise give. For example, during data collection, if the sample isn;t good enough or if the outliers were removed during data cleaning or so on, it will result in a p-value/other statistic value that isn't really interpretable.  <br>\n",
    "For example, if we have a hypothesis and we are managing our data and see that it isn't really making much sense so we take a smaller sample of a section of that data and then find the statistic, this is a form of hacking. We get another result that isn't really correct.  <br>\n",
    "Another problem with this is that there isn't really any way to check it as most researchers just give information on how the final p value was calculated. They do not provide all the other methods used, all the other analysis done, all the other p-values calculated. So, it is really difficult to see if a statistic is hacked until someone else carries out the same study, sometimes years later and gets a different result. That makes a study very in-interpretable.  <br>\n",
    "Another way of p-hacking can be caused by asking the wrong questions. Like, instead of a > H0 for the alternate hypothesis on a one sided test, we choose a < H0 as our alternate hypothesis on the one-sided test.  <br>\n",
    "**P value is the measure of surprise. The lower it is, the more surprised we are at our data because of how we choose our Null Hypothesis. We will never be surprised at our hypothesis as we make those before we collect our data. We get surprised with a low p-value because the data does not fall in line with our default action, i.e. our Null Hypothesis**\n",
    " <br>\n",
    " \n",
    " **p_hacking refers to testing multiple observations on the same data until one of them is statistically significant and then publish or present those results as mathematically valid conclusion. THIS IS WRONG. Plan your test ahead, define relevant segmentation before chosing a p-value, don;t peek into your data.** <br>\n",
    " \n",
    " **Hypotheses are “guesses” about model and data structure that we want to test from sample data. Hypothesis Testing is statistical term for how to do so in mathematically meaningful way, but we do so all the time even in daily experience without realizing.** If TV isn’t working and you restarted the set-top-box, you have just tested a hypothesis. Hypothesis was that cause of TV not working lies in set-top-box, and restarting is way to test if that is correct. If your observations (result after restarting) align with your hypothesis (TV starts working or gets better), then you have more confidence in hypothesis. Then you may test another. **Problem solving is essentially serial hypothesis testing.** As we discussed in previous post on [“11 facts of data science“](https://www.edupristine.com/blog/11-facts-about-data-science), alternative to hypothesis testing is trial-and-error, where you will just tinker with everything and hope that something works.\n",
    "\n",
    "In statistical terms hypothesis testing refers to having a prior belief (called Null Hypothesis), observing data and doing certain calculations on it, and seeking strong enough evidence to falsify prior belief (reject Null Hypothesis). Recall that **in practice there is never certain, or 100%, evidence for anything** – even that Sun will rise tomorrow – but only strong enough, say, 99.9…9%. **There is slight risk inherent in rejecting null hypothesis without certainty, and that risk is represented as confidence level of α (alpha).** There is, naturally, alternate risk of being too stubborn and demanding too much evidence, that we stick to prior belief even in presence of extraordinary evidence otherwise. That risk is less talked about, and is represented as β (beta) or power of the test (1-β ). \n",
    "\n",
    "How small chance can you afford depends entirely on practical risk of making wrong decision. What if you claim someone has cancer when he doesn't? What about claiming he doesn't  when does? Which is more risky? What about declining valid credit card transaction thinking it is fraud? What about not declining and actually risking fraud? **Since α and β always play against each other, there is trade off in risk of false positive and false negative.** Depending on your application you may accept anywhere from 20% to 0.001% risk in rejecting null hypothesis falsely. If your application isn’t specific, or both errors are equally bad, then statistical rule of thumb has emerged for α=5%. That means, about 1 in 20 times you will reject null hypothesis falsely just because sample happens to be on right on black line.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
